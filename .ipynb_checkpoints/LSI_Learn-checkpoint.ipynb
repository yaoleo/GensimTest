{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LSI 概念\n",
    "\n",
    "LSI(Latent Semantic Indexing)，中文意译是潜在语义索引，即通过海量文献找出词汇之间的关系。\n",
    "\n",
    "基本理念是当两个词或一组词大量出现在一个文档中时，这些词之间就是语义相关的。\n",
    "\n",
    "有的文章也叫Latent Semantic  Analysis（LSA）。其实是一个东西，后面我们统称LSI，它是一种简单实用的主题模型。\n",
    "\n",
    "LSI是基于奇异值分解（SVD-Singular Value Decomposition）的方法来得到文本的主题的。\n",
    "\n",
    "## 什么是SVD？\n",
    "\n",
    "参考：http://www.cnblogs.com/pinard/p/6251584.html\n",
    "\n",
    "## LSI 理解\n",
    "对于一个m×n的矩阵A，可以分解为下面三个矩阵：\n",
    "\n",
    "\tAm×n=Um×mΣm×nVn×nT\n",
    "有时为了降低矩阵的维度到k，SVD的分解可以近似的写为：\n",
    "\n",
    "\tAm×n≈Um×kΣk×kVk×nT\n",
    "\n",
    "输入的有m个文本，每个文本有n个词。\n",
    "\n",
    "而Aij则对应第i个文本的第j个词的特征值，这里最常用的是基于预处理后的标准化TF-IDF值。\n",
    "k是我们假设的主题数，一般要比文本数少。\n",
    "\n",
    "SVD分解后，\n",
    "Uil对应第i个文本和第l个主题的相关度。\n",
    "Σlm对应第l个主题和第m个词义的相关度。\n",
    "Vmj对应第m个词义和第j个词的相关度。\n",
    "\n",
    "反过来解释：\n",
    "\n",
    "输入的有m个词，对应n个文本。\n",
    "而Aij则对应第i个词档的第j个文本的特征值，这里最常用的是基于预处理后的标准化TF-IDF值。\n",
    "k是我们假设的主题数，一般要比文本数少。\n",
    "SVD分解后，\n",
    "Uil对应第i个词和第l个词义的相关度。\n",
    "Σlm对应第l个词义和第m个主题的相关度。\n",
    "Vjm对应第j个文本和第m个主题的相关度。\n",
    "\n",
    "\n",
    "这样我们通过一次SVD，就可以得到文档和主题的相关度，词和词义的相关度以及词义和主题的相关度。\n",
    "\n",
    "## LSI计算文本相似度\n",
    "\n",
    "通过余弦相似度：\n",
    "\n",
    "参考：http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## LSI主题模型总结\n",
    "\n",
    "LSI是最早出现的主题模型了，它的算法原理很简单，一次奇异值分解就可以得到主题模型，同时解决词义的问题，非常漂亮。\n",
    "\n",
    "但是LSI有很多不足，导致它在当前实际的主题模型中已基本不再使用。\n",
    "主要的问题有：\n",
    "+ SVD计算非常的耗时，尤其是我们的文本处理，词和文本数都是非常大的，对于这样的高维度矩阵做奇异值分解是非常难的。\n",
    "+ 主题值的选取对结果的影响非常大，很难选择合适的k值。\n",
    "+ LSI得到的不是一个概率模型，缺乏统计基础，结果难以直观的解释。\n",
    "\n",
    "对于问题1），主题模型非负矩阵分解（NMF）可以解决矩阵分解的速度问题。\n",
    "对于问题2），这是老大难了，大部分主题模型的主题的个数选取一般都是凭经验的，较新的层次狄利克雷过程（HDP）可以自动选择主题个数。\n",
    "对于问题3），牛人们整出了pLSI(也叫pLSA)和隐含狄利克雷分布(LDA)这类基于概率分布的主题模型来替代基于矩阵分解的主题模型。\n",
    "\n",
    "回到LSI本身，对于一些规模较小的问题，如果想快速粗粒度的找出一些主题分布的关系，则LSI是比较好的一个选择，其他时候，如果你需要使用主题模型，推荐使用LDA和HDP。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "# 防止乱码\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "# 打印log信息\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取分词后的文件\n",
    "\n",
    "import re  \n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        #for line in open('mycorpus.txt'):\n",
    "        for line in open('2016G201000_result.txt'):\n",
    "            #print line\n",
    "            \n",
    "  \n",
    "            line = re.findall(ur\"[\\u4e00-\\u9fa5]+\", line.decode(\"utf-8\"))\n",
    "            yield [text for text in line]\n",
    "            #yield line.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "Corp = MyCorpus() # doesn't load the corpus into memory!\n",
    "for i in Corp:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 预处理\n",
    "def preHandle(Corp):\n",
    "    # remove common words and tokenize\n",
    "    Corp = [x for x in Corp if x != []]\n",
    "    stoplist = set('for a of the and to in rec trs docformat imageflag lasttime confid simrank simflag urltime  pagelevel pagerank infotype  purlid startid istop page / < > br gt p & nbsp = utf - ? xml ( # ! pcdata ) * | element lt ; : tbody tr td'.split())\n",
    "    Corpn = [[word.encode('utf-8') for word in document if word not in stoplist]\n",
    "             for document in Corp]\n",
    "    \n",
    "    # remove words that appear only once\n",
    "    from collections import defaultdict\n",
    "    frequency = defaultdict(int)\n",
    "    for text in Corpn:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "\n",
    "    texts = [[token for token in text if frequency[token] > 1] for text in Corpn]\n",
    "    #for i in range(0,500):\n",
    "        #print i,texts[i]\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = preHandle(Corp)\n",
    "for x in texts:\n",
    "    for i in x:\n",
    "        print i,\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽取一个bag-of-words，将文档的token映射为id\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# 保存词典\n",
    "dictionary.save('2016G201000_result_LSI.dict')\n",
    "print dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 产生文档向量，将用字符串表示的文档转换为用id和词频表示的文档向量\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于这些“训练文档”计算一个TF-IDF模型\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 转化文档向量，将用词频表示的文档向量表示为一个用tf-idf值表示的文档向量\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练LSI模型 即将训练文档向量组成的矩阵SVD分解，并做一个秩为2的近似SVD分解\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'-0.996*\"\\u56fd\\u5185\" + -0.089*\"\\u7b80\\u62a5\" + -0.002*\"\\u7684\" + -0.002*\"\\u56fd\\u9645\" + -0.002*\"\\u7ecf\\u6d4e\" + -0.002*\"\\u4e2d\\u56fd\" + -0.001*\"\\u5728\" + -0.001*\"\\u548c\" + -0.001*\"\\u53d1\\u5c55\" + -0.001*\"\\u5c06\"'),\n",
       " (1,\n",
       "  u'0.994*\"\\u56fd\\u9645\" + 0.034*\"\\u7684\" + 0.026*\"\\u7ecf\\u6d4e\" + 0.023*\"\\u4e2d\\u56fd\" + 0.021*\"\\u5cf0\\u4f1a\" + 0.020*\"\\u4e16\\u754c\" + 0.019*\"\\u548c\" + 0.018*\"\\u5168\\u7403\" + 0.018*\"\\u5728\" + 0.017*\"\\u53d1\\u5c55\"'),\n",
       " (2,\n",
       "  u'-0.728*\"\\u8054\\u5408\\u62a5\" + -0.685*\"\\u53f0\\u6e7e\" + -0.006*\"\\u7684\" + -0.004*\"\\u7ecf\\u6d4e\" + -0.004*\"\\u4e2d\\u56fd\" + -0.003*\"\\u5728\" + -0.003*\"\\u5cf0\\u4f1a\" + 0.003*\"\\u56fd\\u9645\" + -0.003*\"\\u676d\\u5dde\" + -0.003*\"\\u4e16\\u754c\"'),\n",
       " (3,\n",
       "  u'0.725*\"\\u65b0\\u95fb\\u7f51\" + 0.683*\"\\u591a\\u7ef4\" + 0.048*\"\\u4e16\\u754c\" + 0.021*\"\\u7684\" + 0.019*\"\\u7ecf\\u6d4e\" + 0.017*\"\\u9999\\u6e2f\" + 0.015*\"\\u4e2d\\u56fd\" + 0.014*\"\\u5cf0\\u4f1a\" + 0.012*\"\\u676d\\u5dde\" + 0.012*\"\\u5728\"'),\n",
       " (4,\n",
       "  u'-0.295*\"\\u7684\" + -0.234*\"\\u7ecf\\u6d4e\" + -0.199*\"\\u4e2d\\u56fd\" + -0.191*\"\\u5cf0\\u4f1a\" + -0.172*\"\\u4e16\\u754c\" + -0.164*\"\\u5728\" + -0.160*\"\\u676d\\u5dde\" + -0.153*\"\\u53d1\\u5c55\" + -0.152*\"\\u5168\\u7403\" + -0.152*\"\\u548c\"'),\n",
       " (5,\n",
       "  u'-0.753*\"\\u7f51\" + -0.569*\"\\u4e2d\\u8bc4\" + -0.190*\"\\u4fc4\\u7f57\\u65af\" + -0.186*\"\\u536b\\u661f\" + -0.123*\"\\u53c2\\u4e0e\" + -0.099*\"\\u6d88\\u606f\\u62a5\" + 0.032*\"\\u7684\" + 0.030*\"\\u7ecf\\u6d4e\" + -0.028*\"\\u660e\\u955c\" + 0.022*\"\\u4e16\\u754c\"'),\n",
       " (6,\n",
       "  u'0.725*\"\\u6d88\\u606f\\u62a5\" + 0.615*\"\\u4fc4\\u7f57\\u65af\" + -0.224*\"\\u4e2d\\u8bc4\" + 0.136*\"\\u536b\\u661f\" + -0.119*\"\\u7f51\" + 0.043*\"\\u7f8e\\u56fd\" + -0.035*\"\\u53c2\\u4e0e\" + -0.034*\"\\u7ecf\\u6d4e\" + 0.030*\"\\u666e\\u4eac\" + -0.027*\"\\u4e16\\u754c\"'),\n",
       " (7,\n",
       "  u'-0.911*\"\\u7f8e\\u56fd\" + -0.313*\"\\u4e2d\\u6587\\u7f51\" + 0.091*\"\\u7ecf\\u6d4e\" + 0.073*\"\\u4e16\\u754c\" + -0.062*\"\\u603b\\u7edf\" + -0.060*\"\\u5965\\u5df4\\u9a6c\" + 0.060*\"\\u6d88\\u606f\\u62a5\" + 0.057*\"\\u5168\\u7403\" + 0.056*\"\\u53d1\\u5c55\" + 0.054*\"\\u589e\\u957f\"'),\n",
       " (8,\n",
       "  u'0.715*\"\\u81ea\\u7531\" + 0.693*\"\\u4e9a\\u6d32\" + -0.075*\"\\u7f8e\\u56fd\" + -0.028*\"\\u4e2d\\u6587\\u7f51\" + -0.011*\"\\u5cf0\\u4f1a\" + -0.011*\"\\u676d\\u5dde\" + -0.010*\"\\u7ecf\\u6d4e\" + -0.009*\"\\u4e16\\u754c\" + -0.008*\"\\u589e\\u957f\" + 0.008*\"\\u5fae\"'),\n",
       " (9,\n",
       "  u'-1.000*\"\\u6d4b\\u8bd5\" + -0.002*\"\\u5bfc\\u5f39\" + -0.001*\"\\u671d\\u9c9c\" + -0.001*\"\\u4e2d\\u77ed\\u7a0b\" + -0.001*\"\\u4e00\\u6b21\" + -0.001*\"\\u8bd5\\u5c04\" + -0.001*\"\\u53d1\\u751f\" + -0.001*\"\\u4e00\\u5171\" + -0.001*\"\\u81ea\\u4ece\" + -0.001*\"\\u9886\\u57df\"'),\n",
       " (10,\n",
       "  u'1.000*\"\\u5927\\u516c\\u62a5\" + 0.002*\"\\u56fd\\u5bb4\" + 0.001*\"\\u56fe\\u6848\" + 0.001*\"\\u74f7\\u5668\" + 0.001*\"\\u9910\\u5177\" + 0.001*\"\\u5199\\u610f\" + 0.001*\"\\u8bbe\\u8ba1\" + 0.001*\"\\u8bb0\\u8005\" + 0.001*\"\\u897f\\u6e56\" + -0.001*\"\\u7ecf\\u6d4e\"'),\n",
       " (11,\n",
       "  u'-0.327*\"\\u7ecf\\u6d4e\" + 0.317*\"\\u65e5\" + 0.286*\"\\u6708\" + -0.253*\"\\u4e16\\u754c\" + -0.208*\"\\u589e\\u957f\" + 0.205*\"\\u5e74\" + -0.185*\"\\u5168\\u7403\" + -0.173*\"\\u521b\\u65b0\" + -0.159*\"\\u7f8e\\u56fd\" + -0.148*\"\\u53d1\\u5c55\"'),\n",
       " (12,\n",
       "  u'-0.999*\"\\u535a\\u8baf\" + -0.013*\"\\u7ecf\\u6d4e\" + 0.012*\"\\u65e5\" + 0.010*\"\\u6708\" + -0.010*\"\\u4e16\\u754c\" + -0.008*\"\\u589e\\u957f\" + -0.007*\"\\u5168\\u7403\" + -0.007*\"\\u521b\\u65b0\" + 0.007*\"\\u603b\\u7edf\" + 0.007*\"\\u5e74\"'),\n",
       " (13,\n",
       "  u'-0.996*\"\\u7b80\\u62a5\" + 0.089*\"\\u56fd\\u5185\" + -0.005*\"\\u676d\\u5dde\" + -0.004*\"\\u5cf0\\u4f1a\" + -0.004*\"\\u65e5\" + -0.004*\"\\u6708\" + 0.003*\"\\u7684\" + -0.003*\"\\u9886\\u5bfc\\u4eba\" + -0.003*\"\\u5e74\" + -0.003*\"\\u4e8c\"'),\n",
       " (14,\n",
       "  u'0.431*\"\\u536b\\u661f\" + -0.392*\"\\u4e2d\\u8bc4\" + -0.280*\"\\u6d88\\u606f\\u62a5\" + -0.266*\"\\u65e5\" + -0.242*\"\\u6708\" + -0.210*\"\\u5e74\" + -0.196*\"\\u676d\\u5dde\" + 0.170*\"\\u53c2\\u4e0e\" + 0.163*\"\\u7f51\" + -0.155*\"\\u5cf0\\u4f1a\"'),\n",
       " (15,\n",
       "  u'0.454*\"\\u536b\\u661f\" + -0.394*\"\\u4e2d\\u8bc4\" + -0.269*\"\\u6d88\\u606f\\u62a5\" + 0.200*\"\\u676d\\u5dde\" + 0.192*\"\\u65e5\" + -0.174*\"\\u7684\" + 0.169*\"\\u6708\" + 0.167*\"\\u7f51\" + 0.161*\"\\u5cf0\\u4f1a\" + 0.148*\"\\u9886\\u5bfc\\u4eba\"'),\n",
       " (16,\n",
       "  u'-0.712*\"\\u9999\\u6e2f\" + -0.697*\"\\u6587\\u6c47\\u62a5\" + 0.040*\"\\u591a\\u7ef4\" + -0.021*\"\\u65b0\\u95fb\\u7f51\" + -0.018*\"\\u5546\\u62a5\" + -0.017*\"\\u667a\\u5e93\" + -0.017*\"\\u521b\\u65b0\" + -0.015*\"\\u65e5\" + -0.014*\"\\u6881\\u632f\\u82f1\" + -0.014*\"\\u6708\"'),\n",
       " (17,\n",
       "  u'-0.999*\"\\u4e2d\\u592e\\u65e5\\u62a5\" + -0.022*\"\\u97e9\\u56fd\" + 0.009*\"\\u7684\" + -0.009*\"\\u7ecf\\u6d4e\" + -0.008*\"\\u4e16\\u754c\" + -0.008*\"\\u536b\\u661f\" + -0.008*\"\\u65e5\" + 0.007*\"\\u4e2d\\u8bc4\" + -0.007*\"\\u676d\\u5dde\" + -0.007*\"\\u589e\\u957f\"'),\n",
       " (18,\n",
       "  u'-0.429*\"\\u5e74\" + -0.381*\"\\u6708\" + -0.350*\"\\u65e5\" + 0.247*\"\\u676d\\u5dde\" + 0.230*\"\\u9886\\u5bfc\\u4eba\" + 0.215*\"\\u5cf0\\u4f1a\" + 0.209*\"\\u4e60\\u8fd1\\u5e73\" + 0.161*\"\\u96c6\\u56e2\" + 0.155*\"\\u603b\\u7edf\" + 0.132*\"\\u4f1a\\u6664\"'),\n",
       " (19,\n",
       "  u'-0.475*\"\\u62a5\\u4e1a\" + -0.461*\"\\u96c6\\u56e2\" + -0.460*\"\\u4e2d\\u6587\" + -0.454*\"\\u6fb3\\u6d32\" + -0.132*\"\\u56fd\" + 0.129*\"\\u4e8c\" + 0.128*\"\\u5341\\u56fd\\u96c6\\u56e2\" + 0.094*\"\\u5cf0\\u4f1a\" + -0.086*\"\\u8bc4\\u8bba\" + 0.085*\"\\u676d\\u5dde\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "lsi.save('LSI.pkl')\n",
    "lsi.print_topics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
